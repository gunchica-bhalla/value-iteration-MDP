# -*- coding: utf-8 -*-
"""MSCI 531 Software Exploration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rdyxVub5FHcw2XHyw9Wl8ptd1jkzWdvM
"""

pip install pymdptoolbox

#Maintenance Example from Class
import mdptoolbox
import numpy as np

l = 0.9 # Discount factor, epsilon is 0.01 by default
# A: Number of Actions, S: Number of States
#Define the Transistion matrix (A × S × S)
#For the unreachable states the sum of the row should be 1 (to maintain the stochasticity of the transient matrix), 
#thus for unreachable states assign value 1 at s,s position
# Actions {1:Do Nothing, 2:Overhaul, 3:Replace}
#States {0:Excelent ,1:Good ,2:Average,3:Bad}
P = np.array([
              [
              #Action 1
              [0,0.875,0.0625,0.0625], #s0
              [0,0.75,0.125,0.125], #s1
              [0,0,0.5,0.5], #s2
              [0,0,0,1]], #s3
             #Action 2
             [[1,0,0,0], #s0
              [0,1,0,0], #s1
              [0,1,0,0], #s2
              [0,0,0,1] #s3
            ],
            #Action 3
            [[1,0,0,0], #s0
              [1,0,0,0],#s1
              [1,0,0,0], #s2
              [1,0,0,0] #s3
            ]
             ]
  )
 # Define rewars matrix (S × A)
R = np.mat([
            [0, -4000, -6000],
            [-1000, -4000, -6000],
            [-3000, -4000,-6000],
            [-3000, -4000, -6000]
])
vt = mdptoolbox.mdp.ValueIteration(P, R, l)
vt.setVerbose() # display v-variation at each iteration
vt.run() # run the value iteration algorithm
expected = (0,0,0,0)

print("Policy:",vt.policy)

finalV = []
for k in range(len(expected)):
  finalV.append(round(vt.V[k],2))

print("Rewards:",vt.V)
print("Number of Iterations:",vt.iter)